# -*- coding: utf-8 -*-
"""Test_classification_pipeline.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1zBACeeSeWeK0HklAIQ4c371KVCvz2axJ
"""

!pip install transformers



# Commented out IPython magic to ensure Python compatibility.
!pip install transformers

from google.colab import drive
drive.mount('/content/drive')

# Import needed library
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
# %matplotlib inline
import seaborn as sns

from transformers import pipeline

from sklearn.metrics import accuracy_score, balanced_accuracy_score, confusion_matrix, plot_confusion_matrix

from time import time
import datetime
from warnings import filterwarnings
filterwarnings("once", category=DeprecationWarning) # Display just the first matching deprecation warnings (e.g. warning that multi_class is changing to multi_label)

#Needed Function
def plot_conf_mat (y_true, y_pred, cmap="YlGnBu", ax=None, cm_perc=True):
      """
      Function for ploting confusion matrix
      :param array y_true: True classes, shape = [n_samples].
      :param array y_pred: Predicted classes, shape = [n_samples]. 
      :param string cmap: color palette.
      :param  Axes object ax: subplot axis.
      :param bool cm_perc: if true the percentage accuracy is plot.
      :return: (`matplotlib plot object`): the confusion matrix plot
      """
      mat = confusion_matrix(y_true, y_pred, labels=np.unique(y_true))
      mat_sum = np.sum(mat, axis=1, keepdims=True)      #sum across rows (actual label) and retain the matrix dimesion in the return array
      mat_perc = mat / mat_sum.astype(float) * 100

      if cm_perc:
          mat_df = pd.DataFrame(mat_perc, index=np.unique(y_true), columns=np.unique(y_true))
      else:
          mat_df = pd.DataFrame(mat, index=np.unique(y_true), columns=np.unique(y_true))
      mat_df.index.name = 'Actual'
      mat_df.columns.name = 'Predicted'

      sns.heatmap(mat_df,
                  cmap= cmap,                             # color palette
                  annot=True,                             # to display the values 
                  fmt='.1f',                              # round up the values
                  linewidths=.5,                          # Add lines between the cells
                  annot_kws={"size": 15},                 # font size
                  ax=ax,
                  cbar_kws={"shrink": .70,                # adjust the size of the sidebar 
#                              "orientation": "horizontal"  # change the sidebar position
                  }, 
      )

# Read data
url = 'https://raw.githubusercontent.com/CDU-data-science-team/pxtextmining/main/datasets/text_data.csv'
data = pd.read_csv(url, usecols=['feedback', 'label'],  encoding='utf-8')#, nrows=100)
# df = data.sample(1000).reset_index(drop=True)
df = data.loc[8999:,:].reset_index(drop=True)                             #***TESTING****

# Fill missing values with 'Nothing'
df.fillna('Nothing', inplace=True)
print(df.shape)
print(df.head())

# Define the classifcation pipeline for prediction
pretrained_model_name_or_path = '/content/drive/MyDrive/Colab Notebooks/best_model' # the folder directory the pretrained model is saved
classifier = pipeline("text-classification", model=pretrained_model_name_or_path)

# Make prediction
new_label = []
for i in range(len(df)):
  result = classifier(df.feedback[i], padding = True)
  new_label.append(result[0]['label'])
df['new_label'] = new_label

# Explore the metrics
print(df.head(10))
print(f'Accuracy Score: {accuracy_score(df.label, df.new_label)}')
print(f'balanced Accuracy Score: {balanced_accuracy_score(df.label, df.new_label)}')
plot_conf_mat(df.label, df.new_label)

# Commented out IPython magic to ensure Python compatibility.
# %%time
#

