{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Weak_Supervision-Snorkel.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1Q6l8Yhflm6ZpFeZu4VYNbwhZk8SseVB6","authorship_tag":"ABX9TyNzidxOEs9Yr/5ojlYyP1KE"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IGNbCps-0mjD","executionInfo":{"status":"ok","timestamp":1631542868911,"user_tz":-60,"elapsed":6083,"user":{"displayName":"Segun Apejoye","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjPq7lGIw-44SPnH3lXNYGE6KUW64_HqZ6KPvwp=s64","userId":"00855960206580987926"}},"outputId":"e63ec855-9fac-4ff3-99a3-baadb16545b9"},"source":["!pip install snorkel\n","!pip install utils"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: snorkel in /usr/local/lib/python3.7/dist-packages (0.9.7)\n","Requirement already satisfied: scikit-learn<0.25.0,>=0.20.2 in /usr/local/lib/python3.7/dist-packages (from snorkel) (0.22.2.post1)\n","Requirement already satisfied: munkres>=1.0.6 in /usr/local/lib/python3.7/dist-packages (from snorkel) (1.1.4)\n","Requirement already satisfied: scipy<2.0.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from snorkel) (1.4.1)\n","Requirement already satisfied: tqdm<5.0.0,>=4.33.0 in /usr/local/lib/python3.7/dist-packages (from snorkel) (4.62.0)\n","Requirement already satisfied: pandas<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from snorkel) (1.1.5)\n","Requirement already satisfied: tensorboard<2.0.0,>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from snorkel) (1.15.0)\n","Requirement already satisfied: networkx<2.4,>=2.2 in /usr/local/lib/python3.7/dist-packages (from snorkel) (2.3)\n","Requirement already satisfied: torch<2.0.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from snorkel) (1.9.0+cu102)\n","Requirement already satisfied: numpy<1.20.0,>=1.16.5 in /usr/local/lib/python3.7/dist-packages (from snorkel) (1.19.5)\n","Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from networkx<2.4,>=2.2->snorkel) (4.4.2)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas<2.0.0,>=1.0.0->snorkel) (2.8.2)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas<2.0.0,>=1.0.0->snorkel) (2018.9)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas<2.0.0,>=1.0.0->snorkel) (1.15.0)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn<0.25.0,>=0.20.2->snorkel) (1.0.1)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.0.0,>=1.14.0->snorkel) (1.0.1)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.0.0,>=1.14.0->snorkel) (0.12.0)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.0.0,>=1.14.0->snorkel) (57.4.0)\n","Requirement already satisfied: grpcio>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.0.0,>=1.14.0->snorkel) (1.39.0)\n","Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.0.0,>=1.14.0->snorkel) (3.17.3)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.0.0,>=1.14.0->snorkel) (3.3.4)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.0.0,>=1.14.0->snorkel) (0.37.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.0.0,>=1.14.0->snorkel) (4.6.4)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch<2.0.0,>=1.2.0->snorkel) (3.7.4.3)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard<2.0.0,>=1.14.0->snorkel) (3.5.0)\n","Requirement already satisfied: utils in /usr/local/lib/python3.7/dist-packages (1.0.1)\n"]}]},{"cell_type":"code","metadata":{"id":"9x-htlTliGiM"},"source":["# import needed libraries \n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","#from snorkel.labeling import labeling_function\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KPaOSca2hvm6"},"source":["# Load the data and Preprocess it\n","\n","if avalaible, small set of hand-labeled dataset will be useful as test set, needed for validating our classifier later"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bsHMRB6u9So8","executionInfo":{"status":"ok","timestamp":1631542920222,"user_tz":-60,"elapsed":553,"user":{"displayName":"Segun Apejoye","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjPq7lGIw-44SPnH3lXNYGE6KUW64_HqZ6KPvwp=s64","userId":"00855960206580987926"}},"outputId":"ec69725c-a5d0-4350-b498-1ff860e38971"},"source":["# Load the dataset\n","# Load and Preprocess the data\n","filepath = 'https://raw.githubusercontent.com/CDU-data-science-team/pxtextmining/main/datasets/text_data.csv'\n","df = pd.read_csv(filepath, usecols=['feedback', 'label'])#, nrows=100)\n","print(f'{df.head()} \\n\\nno. of rows, columes: {df.shape} \\n')\n","\n","#  take a sample to easily test pipeline\n","# df = df.sample(100)\n","\n","#fill missing value has this causes runtime error while fiting the model \n","print(f'Missing values\\n{df.isna().sum()}')\n","df['feedback'].fillna('Nothing', inplace = True)\n","print(df.isna().sum())\n","\n","df_train = df"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(9291, 2)\n"]}]},{"cell_type":"markdown","metadata":{"id":"TU-iHMFvEMUZ"},"source":["### Pipeline testing data"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":202},"id":"mmDTky3ghLE_","executionInfo":{"status":"ok","timestamp":1631542924292,"user_tz":-60,"elapsed":304,"user":{"displayName":"Segun Apejoye","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjPq7lGIw-44SPnH3lXNYGE6KUW64_HqZ6KPvwp=s64","userId":"00855960206580987926"}},"outputId":"8e8c900e-f7fc-492c-b0fe-1dc73ce2128b"},"source":["# Define the label mappings for convenience\n","ABSTAIN = -1\n","NOT_SPAM = 0\n","SPAM = 1\n","\n","#generate sample labels for testing current pipeline\n","import random\n","\n","df_train['label'] =  [random.choice([SPAM, NOT_SPAM, ABSTAIN]) for _ in df_train.label]   # generate random label\n","df_train.rename(columns = {'feedback':'text'}, inplace = True)  # change the column name from feedback to text\n","df_train.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>label</th>\n","      <th>text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>Nothing.</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>Temperature in theatre a little low.</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1</td>\n","      <td>Same service available at Bingham Health Centre.</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>Appointment details given over phone - no phys...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>On one occasion I was not made aware that my a...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   label                                               text\n","0      0                                           Nothing.\n","1      0               Temperature in theatre a little low.\n","2      1   Same service available at Bingham Health Centre.\n","3      0  Appointment details given over phone - no phys...\n","4      0  On one occasion I was not made aware that my a..."]},"metadata":{},"execution_count":6}]},{"cell_type":"markdown","metadata":{"id":"16Kyu7N-jIwv"},"source":["# Labeling Functions\n","This are noisy, programmatic rules and heuristics that assign labels to unlabeled training data. They help users __encode domain knowledge__ and other supervision sources programmatically.\n","\n","\n","---\n","## Recommended practice for LF development\n","Typical LF development cycles include multiple iterations of ideation, refining, evaluation, and debugging. A typical cycle consists of the following steps:\n","\n","\n","\n","1.   Look at examples to generate ideas for LFs\n","2.   Write an initial version of an LF\n","3. Spot check its performance by looking at its output on data points in the training set (or development set if available)\n","4. Refine and debug to improve coverage or accuracy as necessary\n","\n","The goal for LF development is to create a high quality set of training labels for our unlabeled dataset, not to label everything or directly create a model for inference using the LFs. The training labels are used to train a separate discriminative model (in this case, one which just uses the comment text) in order to generalize to new, unseen data points. Using this model, we can make predictions for data points that our LFs don’t cover.\n"]},{"cell_type":"markdown","metadata":{"id":"eQYgy146hMOu"},"source":["### Writing series of Labeling Functions"]},{"cell_type":"code","metadata":{"id":"PS3QPn0Cht2-"},"source":["from snorkel.labeling import labeling_function\n","\n","# Below are examples of rules been converted into functions (speak to SME's to set the rules)\n","\n","# Keyword matches:\n","@labeling_function()\n","def lf_keyword_my(x):\n","    \"\"\"Many spam comments talk about 'my channel', 'my video', etc.\"\"\"\n","    return SPAM if \"my\" in x.text.lower() else ABSTAIN\n","\n","# Regular expressions related rule\n","import re\n","@labeling_function()\n","def lf_regex_check_out(x):\n","    \"\"\"Spam comments say 'check out my video', 'check it out', etc.\"\"\"\n","    return SPAM if re.search(r\"check.*out\", x.text, flags=re.I) else ABSTAIN\n","\n","# Use pre-trained model (we use sentiment analysis here)\n","from textblob import TextBlob\n","@labeling_function()\n","def lf_textblob_polarity(x):\n","    \"\"\"\n","    We use a third-party sentiment classification model, TextBlob.\n","    We combine this with the heuristic that non-spam comments are often positive.\n","    \"\"\"\n","    return NOT_SPAM if TextBlob(x.text).sentiment.polarity > 0.3 else ABSTAIN"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_bdF0GV4umdq"},"source":["## Combine the LFs and apply LabelModel\n","This generate  the initial set of labels and Compare it to original label (if available)\n","\n","we develop a <generative model> using LabelModel to combine the outputs of the LFs and generate noise-aware probabilistic (or confidence-weighted) label per data point"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Tvr0qWhvl0Ac","executionInfo":{"status":"ok","timestamp":1629168766410,"user_tz":-60,"elapsed":3396,"user":{"displayName":"Segun Apejoye","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjPq7lGIw-44SPnH3lXNYGE6KUW64_HqZ6KPvwp=s64","userId":"00855960206580987926"}},"outputId":"a4e731ea-5306-4abf-abc6-ceb9dd05638c"},"source":["from snorkel.labeling.model import LabelModel\n","from snorkel.labeling import PandasLFApplier\n","\n","# Define the set of labeling functions (LFs)\n","lfs = [lf_keyword_my, lf_regex_check_out, lf_textblob_polarity]\n","applier = PandasLFApplier(lfs)\n","\n","# Apply the LFs to the unlabeled training data\n","L_train = applier.apply(df_train)\n","\n","# Use LabelModel to automatically estimate the accuracies and correlations, reweight and combine the LF labels \n","label_model = LabelModel(cardinality=2, verbose=True)   # cardinality is the number of classes\n","label_model.fit(L_train, n_epochs=500, log_freq=50, seed=123)\n","\n","# Generate noise-aware probabilistic set of clean, integrated labels \n","predict_proba\n","probs_train = label_model.predict_proba(L=L_train, tie_break_policy=\"abstain\")    #predict(L) - to Return label predictions (int).\n","# df_train[\"new_label\"] = label_model.predict(L=L_train, tie_break_policy=\"abstain\")  \n","\n","# filter out unlabeled data points (this can hurt our model)\n","# (When all of the labeling functions abstain, the LabelModel abstains as well)\n","from snorkel.labeling import filter_unlabeled_dataframe\n","df_train_filtered, probs_train_filtered = filter_unlabeled_dataframe(\n","    X=df_train, y=probs_train, L=L_train\n",")\n","# or\n","# df_train = df_train[df_train.new_label != ABSTAIN] "],"execution_count":null,"outputs":[{"output_type":"stream","text":["100%|██████████| 9291/9291 [00:03<00:00, 2924.53it/s]\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"wecn7C-QoLeD"},"source":["### Compute labeling accuracy"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wZVXNozMuUGb","executionInfo":{"status":"ok","timestamp":1629169238888,"user_tz":-60,"elapsed":236,"user":{"displayName":"Segun Apejoye","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjPq7lGIw-44SPnH3lXNYGE6KUW64_HqZ6KPvwp=s64","userId":"00855960206580987926"}},"outputId":"50a98587-9333-4c63-ed82-8d70ed6d49a3"},"source":["from sklearn.metrics import accuracy_score, balanced_accuracy_score, confusion_matrix, plot_confusion_matrix\n","\n","preds_test = probs_to_preds(probs_train_filtered)\n","balanced_score = balanced_accuracy_score(df_train.label, preds_test)\n","acc_score = accuracy_score(df_train.label, preds_test) \n","# or \n","# label_model.score(L=L_test, Y=Y_test, tie_break_policy=\"random\")[\"accuracy\"]\n","\n","print(acc_score, balanced_score)\n","\n","\n","# balanced_score = balanced_accuracy_score(df_train.label, df_train.new_label)\n","# acc_score = accuracy_score(df_train.label, df_train.new_label) \n","# or "],"execution_count":null,"outputs":[{"output_type":"stream","text":["0.3315036056398665 0.3318184225490089\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"QSWXXSBBudCx"},"source":["## Final model for Label generation and future Labeling (using Discriminative Model)"]},{"cell_type":"markdown","metadata":{"id":"yBcv1yQbpZ4F"},"source":["We train a machine learning model that can generalize beyond the coverage of the labeling functions and the LabelModel\n","\n","For this, we can augment the existing labeled training datasets by creating transformed copies of the data points. **Data augmentation** is a practical and powerful method for injecting information about domain invariances into ML models via the data, rather than by trying to modify their internal architectures. e.g. randomly replacing a word with a synonym. We use the `transformation_function` (TF) for this purpose:"]},{"cell_type":"markdown","metadata":{"id":"bLNm9hVxrNkG"},"source":["### Model Training\n","***Training Set***: The largest split of the dataset, and the one without any ground truth (“gold”) labels. We will generate labels for these data points with weak supervision.\n","\n","***Test Set***: this is a small, standard held-out blind hand-labeled set for final evaluation of our discriminative classifier. This set should only be used for final evaluation, not error analysis. Depending on the approach the test set can be further splited into *development (validation) set* and *development split*. the **Development set** is used  for hyperparameter tuning of the end discriminative classifier"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oKrdZDhbrMS6","executionInfo":{"status":"ok","timestamp":1629170476595,"user_tz":-60,"elapsed":5035,"user":{"displayName":"Segun Apejoye","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjPq7lGIw-44SPnH3lXNYGE6KUW64_HqZ6KPvwp=s64","userId":"00855960206580987926"}},"outputId":"394145d4-d860-474c-cad9-dc3a5f679aaf"},"source":["from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.linear_model import LogisticRegression\n","\n","# split the data into train and test set (for demostration purpose)\n","train_sample = 6000\n","train_text = df_train.text.tolist()[:train_sample]\n","test_text = df_train.text.tolist()[train_sample:]\n","\n","# preprocess the data\n","#X_train = CountVectorizer(ngram_range=(1, 2)).fit_transform(train_text)\n","pre_pro = CountVectorizer(ngram_range=(1, 2)).fit(train_text)\n","X_train = pre_pro.transform(train_text)\n","X_test = pre_pro.transform(test_text)\n","\n","clf = LogisticRegression(solver=\"lbfgs\")\n","clf.fit(X=X_train, y=df_train.label.values[:train_sample])\n","\n","y_true = df_train.label.values[train_sample:]\n","y_pred = clf.predict(X=X_test)\n","m_acc_score = accuracy_score(y_true, y_pred)\n","m_balanced_score = balanced_accuracy_score(y_true, y_pred)\n","\n","print(m_acc_score, m_balanced_score)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["0.3290793072014585 0.3319815389969851\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"],"name":"stderr"}]}]}